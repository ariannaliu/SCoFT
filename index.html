<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project page for SCoFT, owned by the Robotics Institute, CMU, roBot Intelligent Group, Zhixuan Liu, Peter Schaldenbrand, Jean Oh">
  <meta property="og:title" content="SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation"/>
  <meta property="og:description" content="SCoFT leverages the model's intrinsic biases to refine itself, for the purpose of shifting away from misrepresentations of a culture and achieve equitable image generation."/>
  <meta property="og:url" content="https://ariannaliu.github.io/SCoFT/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/scoft_in.png" />
  <meta property="og:image:width" content="1384"/>
  <meta property="og:image:height" content="1170"/>


  <meta name="twitter:title" content="SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation">
  <meta name="twitter:description" content="SCoFT leverages the model's intrinsic biases to refine itself, for the purpose of shifting away from misrepresentations of a culture and achieve equitable image generation.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/scoft_in.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="SCoFT, Cultural Stable Diffusion, Cultural Debias, text-to-image generation, foundation model">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SCoFT</title>
  <link rel="icon" type="image/x-icon" href="static/images/RI_logo.jpeg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://ariannaliu.github.io/" target="_blank">Zhixuan Liu</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://pschaldenbrand.github.io/" target="_blank">Peter Schaldenbrand</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.ri.cmu.edu/ri-people/beverley-claire-okogwu/" target="_blank">Beverley-Claire Okogwu</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://lilydaytoy.github.io/" target="_blank">Wenxuan Peng</a><sup>2</sup>
                  </span>
                  <br>
                  <span class="author-block">
                    <a href="https://www.ml.dongguk.edu/people" target="_blank">Youngsik Yun</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://ahundt.github.io/" target="_blank">Andrew Hundt</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://sites.google.com/view/jihiekim/" target="_blank">Jihie Kim</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.cs.cmu.edu/~./jeanoh/" target="_blank">Jean Oh</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>CMU  &nbsp <sup>2</sup>Nanyang Technological University  &nbsp  <sup>3</sup>Dongguk University<br>Under Review</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ariannaliu/SCoFT" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser_final.jpeg" alt="MY ALT TEXT"/>
      <h2 class="content has-text-justified">
      Stable Diffusion perpetuates harmful stereotypes that assume dirty buildings are representative of some nations, and often generates regionally irrelevant designs. 
      Our approach <strong>decreases stereotypes</strong> and <strong>improves cultural relevance</strong> of generated images and achieves around <strong>80% preferences</strong> in our human evaluation across 5 cultures.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Accurate representation in media is known to improve the well-being of the people who consume it. 
            Generative image models trained on large web-crawled datasets such as LAION are known to produce images with harmful stereotypes and misrepresentations of cultures. 
            We improve inclusive representation in generated images by (1) engaging with communities to collect a culturally representative dataset that we call the <strong>Cross-Cultural Understanding Benchmark (CCUB)</strong>, and we propose (2) a novel <strong>Self-Contrastive Fine-Tuning (SCoFT)</strong> method that leverages the model's known biases to self-improve. 
            SCoFT is designed to encode high-level information from the dataset into the model for the purpose of shifting away from misrepresentations of a culture.
            Our user study conducted on 51 participants from 5 different countries based on their self-selected national cultural affiliation shows that our proposed approach consistently generates images with higher cultural relevance and fewer stereotypes when compared to the Stable Diffusion baseline.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
    <div class="hero-body">
      <div class="container">
      <h2 class="title">Algorithm</h2>
      <h2 class="content has-text-justified">
        Unlike concept editing tasks with specific image editing directions, depicting cultural accuracy remains more abstract and challenging.
        <strong>SCoFT leverages the pre-trained model's cultural misrepresentations to refine itself.</strong>
        We harness the intrinsic biases of large pre-trained models as a rich source of counterexamples; shifting away from these biases gives the model clues towards more accurate cultural concepts.
        Image samples from the pre-trained model are used as negative examples, and CCUB images are used as positive examples, to train the model to discern subtle differences. 
        We de-noise latent codes in several iterations, project them into the pixel space, and then compute the contrastive loss.
        To prevent overfitting for small dataset fine-tuning, a memorization loss is further introduced.
      </h2>
      <div class="container is-max-desktop">
        <img src="static/images/overview_final.jpeg" alt="MY ALT TEXT"/>
      </div>
      
      </div>
    </div>
</section>


<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Culturally-aware SCoFT Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/show_Nigeria.png" alt="show Nigerian results"/>
        <h2 class="subtitle has-text-centered">
          <strong>Nigerian culture:</strong> "Nigerian people in casual clothing nowadays", "dancers are performing for a crowd, in Nigeria",<br> "family is eating together, in Nigeria", "photo of a house, in Nigeria", "photo of a street, in Nigeria",<br> "photo of a bedroom, in Nigeria", "student studying in the classroom, in Nigeria".
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/show_Chinese.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <strong>Chinese culture:</strong> 
          "people are performing traditional instrument, in China", "photo of a school, in China",<br>
          "photo of a street, in China", "family is eating together, in China",
          "two girls wearing Chinese traditional Han dress",<br> "a man and a woman, in China", ``woman is painting in a traditional style, in China".
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/show_Indian.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <strong>Indian culture:</strong> 
          "photo of children in India", "photo of a house, in India",<br>
          "people wearing traditional clothing, in India", "family is eating together, in India", "photo of a street, in India",<br>
          "people walking on the street, in India", "people inside their house, in India".
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/show_Korean.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        <strong>Korean culture:</strong> 
        "photo of a street, in Korea", "photo of a traditional building, in Korea",<br> 
        "people wearing traditional clothing, in Korea", "a table of food in Korea", "a woman is painting in a traditional style, in Korea",<br>
        "musician performing Korean traditional instrument", "photo of a family, in Korea".
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/show_Mexican.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        <strong>Mexican culture:</strong> 
        "photo of a building, in Mexico", "people wearing traditional clothing, in Mexico",<br> 
        "photo of a family, in Mexico", "photo of a school, in Mexico", "university student studying, in Mexico",<br>
        "people performing traditional music instrument, in Mexico", "family is eating together, in Mexico".
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
    <h2 class="title">Ablation</h2>
    <h2 class="content has-text-justified">
      To investigate the effects of each loss function within SCoFT we also <strong>qualitatively compare each ablation</strong> in the left figure.
    <strong>Human evaluation results</strong> is shown in the violin plot of participant rankings across the survey items and countries.
    A wider strip means more answers with that value. Each new loss in our ablation study improved the rankings, and our whole pipeline is best. (Rank 1 is the best; 4, the worst)
    </h2>
    <!-- <div class="container is-max-desktop">
      <img src="static/images/ablation.png" alt="MY ALT TEXT"/>
    </div> -->
    <img src="static/images/ablation_two.png" alt="MY ALT TEXT"/>
    </div>
  </div>
</section>


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
    <h2 class="title">Potential Applications</h2>
    <h2 class="content has-text-justified">
      SCoFT's effectiveness reaches <strong>far beyond demographical cultural</strong> applications. We demonstrate its adaptability by applying it to another fine-tuning domain: our internal <strong>prosthetics dataset</strong>. Here, SCoFT has shown to be particularly effective in generating images that more accurately represent the culture of people with prosthetics.
      <!-- SCoFT's utility extends <strong>beyond demographical cultural</strong> applications. We showcase its versatility by applying it to other fine-tuning domain: our internal the <strong>prosthetics dataset</strong>, where it proves effective in generating more accurate images representing the culture of people with prosthetics. -->
    </h2>
    <div class="container is-max-desktop">
      <img src="static/images/mobility.png" alt="mobility scoft"/>
    </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
    <h2 class="title">Limitations</h2>
    <h2 class="content has-text-justified">
      To tackle the bias in the data, we aim for two goals: (1) to generate accurate images given a specific cultural context and (2) to generate <strong>diverse images given a generic text prompt</strong> without any specific cultural context. 
      Our current approach is focused on achieving the first goal. 
      Our current model can generate promisingly diverse images for some generic prompts <strong><i>"photo of a person"</i></strong> as shown in the figure below when compared to the baseline model that generates biased images.
      Our CCUB dataset was collected by experienced residents; however, to improve the quality of the dataset, more vigorous verification will be needed.
      <strong>We strongly encourage and invite everyone to participate in enriching the CCUB dataset.</strong>
    </h2>
    <div class="container is-max-desktop">
      <img src="static/images/diversity-16.png" alt="diversity in generic prompts"/>
    </div>
    </div>
  </div>
</section>


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->



<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Newest Paper</h2>

      <iframe  src="static/pdfs/SCoFT_pdf_github.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Coming Soon</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
    <h2 class="title">Acknowledgements</h2>
    <h2 class="content has-text-justified">

    </h2>
    </div>
  </div>
</section> -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <h2 class="title">Acknowledgements</h2>

          <p>We are grateful to Lia Coleman, Youeun Shin for their continuous collaboration, to Chaitanya Chawla, Pablo Ortega, Vihaan Misra, Ingrid Navarro, Yu Chen, Jinyun Xu, Jiaji Li, Mingzhu Liu for contributing the CCUB dataset collection, and to Nupur Kumari, Zeyu Qin, Heng Yu, Jinqi Luo for their helpful discussion.
             </p>

          <p>
            This work is in part supported by NSF IIS-2112633. Youngsik Yun, and Jihie Kim were supported by the MSIT (Ministry of Science, ICT), Korea, under the High-Potential Individuals Global Training Program (RS-2022-00155054) supervised by the IITP (Institute for Information & Communications Technology Planning & Evaluation) (50%).
          </p>

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
